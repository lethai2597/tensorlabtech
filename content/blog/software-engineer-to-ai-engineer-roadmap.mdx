---
title: "Roadmap: Từ Software Engineer đến AI Application Engineer"
date: "2026-02-19"
description: "Lộ trình chi tiết cho dev muốn chuyển hướng AI. Từ Prompt Engineering, RAG, Agents đến Production — học gì, dùng gì, làm gì."
---

Xin chào, anh em AI giờ hot quá, kéo theo sẽ là một tá nhu cầu liên quan đến xây dựng hệ thống có sự xuất hiện của AI, các vị trí/công nghệ xuất hiện liên tục. Hằng ngày nghe mấy cái thuật ngữ kiểu Agent, RAG, Tools, Flow, Context... nhiều quá mà chưa hiểu cụ thể nó là gì, nên có tìm hiểu một cái roadmap cho anh em dev muốn có thêm hiểu biết về AI.

Nếu các chuyên gia thấy thiếu hay có lời khuyên gì thì cho chúng mình xin, còn bạn chưa chuyên thấy cái roadmap này hữu ích có thể tham khảo nhé.

<Callout type="tip" title="Tư duy chung">
Hãy tưởng tượng: Hiện tại bạn đang dùng LLM như một Chatbot đơn lẻ. Để trở thành AI Dev, bạn cần biến nó thành một **Hệ điều hành biết suy nghĩ và hành động**.
</Callout>

## Bức tranh tổng thể

Trước khi đi vào lộ trình học, hãy nhìn vào kiến trúc. Một ứng dụng AI không chỉ là `User -> Prompt -> LLM -> Response`. Nó phức tạp hơn nhiều:

| Thành phần | Vai trò | Công nghệ |
|---|---|---|
| Bộ não | Xử lý ngôn ngữ, suy luận | GPT-4, Claude, Llama... |
| Bộ nhớ dài hạn | Lưu trữ knowledge base | Vector Database (RAG) |
| Bộ nhớ ngắn hạn | Quản lý hội thoại | Context management |
| Tay chân | Gọi API, truy xuất DB, lướt web | Agents, Function Calling |
| Dây thần kinh | Kết nối tất cả | LangChain, LlamaIndex |

Dưới đây là lộ trình đi từ mức cơ bản đến nâng cao, qua **5 giai đoạn**: LLM Control → RAG → Orchestration → Agents → Production.

---

## Giai đoạn 1: Kiểm soát "Bộ não" (LLM Control & Interface)

> Mục tiêu: Đảm bảo Input chuẩn và Output dùng được trong code (không phải text rác).

### Prompt Engineering & In-Context Learning

**Cái này là gì?** Không phải là viết văn mẫu. Là kỹ thuật thiết kế input (prompt) sao cho AI hiểu ngữ cảnh, vai trò và format mà không cần train lại model.

**Học để làm gì?** Để giảm thiểu việc AI trả lời sai ("hallucination") và tăng độ chính xác cho các tác vụ suy luận logic.

**Cách học:**
- Học các pattern: **Zero-shot** (hỏi luôn), **Few-shot** (đưa ví dụ mẫu), **Chain-of-Thought** (bảo AI "hãy suy nghĩ từng bước").
- Thực hành trên **OpenAI Playground** hoặc **Anthropic Console** trước khi code.

**Thư viện/Tài liệu:**
- Guide: [promptingguide.ai](https://www.promptingguide.ai/) — "Kinh thánh" của môn này.
- Tool: OpenAI Playground.

<Callout type="info" title="Ví dụ đầu ra">
Một prompt phân loại email khách hàng chính xác: "Đây là email khiếu nại, độ khẩn cấp: Cao, hướng xử lý: Chuyển cho team Tech".
</Callout>

---

### Structured Output (JSON Mode & Zod)

**Cái này là gì?** Ép AI trả về dữ liệu tuân thủ nghiêm ngặt theo một Schema (cấu trúc) JSON định sẵn, thay vì trả về text tự do.

**Học để làm gì?** Đây là **cầu nối quan trọng nhất** với Web Dev. Code backend của bạn cần `JSON.parse()` chứ không thể parse một đoạn văn.

**Cách học:**
- Học cách định nghĩa Schema bằng **Zod** (TypeScript) hoặc JSON Schema.
- Học tham số `response_format` trong API OpenAI.

**Thư viện/Tài liệu:**
- Lib: **Zod** (validate), **Vercel AI SDK** (`generateObject` function).
- Concept: OpenAI Function Calling.

```typescript
// Ví dụ: Dùng Zod + Vercel AI SDK để extract thông tin
import { generateObject } from "ai";
import { z } from "zod";

const schema = z.object({
  name: z.string(),
  skills: z.array(z.string()),
  exp: z.number(),
});

const result = await generateObject({
  model: openai("gpt-4o"),
  schema,
  prompt: "Extract info: Nam, 5 năm kinh nghiệm React và Node",
});
// -> { name: "Nam", skills: ["React", "Node"], exp: 5 }
```

---

## Giai đoạn 2: Nạp dữ liệu ngoài (RAG - Retrieval Augmented Generation)

> Mục tiêu: AI trả lời dựa trên dữ liệu riêng của bạn (File PDF, Database công ty).

### Embeddings & Vector Space

**Cái này là gì?** Kỹ thuật biến văn bản thành danh sách các con số (Vector). Các câu có ý nghĩa giống nhau sẽ có vector gần nhau trong không gian toán học.

**Học để làm gì?** Để máy tính hiểu được "ngữ nghĩa". Ví dụ: Tìm kiếm từ khóa "Con chó" sẽ không ra "Gâu gâu", nhưng tìm kiếm Vector sẽ thấy chúng liên quan nhau.

**Cách học:**
- Tìm hiểu khái niệm **Cosine Similarity** (Độ tương đồng Cosine).
- Gọi API `embeddings` của OpenAI để xem output trông như thế nào.

```typescript
// Ví dụ output của embedding
const vector = await getVector("Quả táo");
// -> [0.012, -0.231, 0.88, ...] (1536 dimensions)
```

**Tài liệu:** [DeepLearning.AI](https://www.deeplearning.ai/) — Course về Embeddings.

---

### Vector Databases (Lưu trữ trí nhớ)

**Cái này là gì?** Loại Database chuyên dụng để lưu và query các vector cực nhanh.

**Học để làm gì?** Thay thế cho `LIKE '%keyword%'` trong SQL. Giúp thực hiện **Semantic Search** (tìm kiếm theo ý hiểu).

| Vector DB | Loại | Phù hợp với |
|---|---|---|
| pgvector | Extension Postgres | Đã dùng Postgres, muốn tích hợp nhanh |
| Pinecone | SaaS (Cloud) | Muốn nhanh gọn, không quản lý infra |
| ChromaDB | Local / Self-hosted | Prototype, chạy local |
| Supabase Vector | SaaS + pgvector | Web Dev, thân thiện nhất |

<Callout type="info" title="Ví dụ đầu ra">
Query: "Tìm các đoạn văn nói về chính sách nghỉ ốm". DB trả về 3 đoạn văn bản liên quan nhất từ file PDF Nhân sự.
</Callout>

---

### Chunking & Ingestion Strategy

**Cái này là gì?** Chiến thuật cắt nhỏ dữ liệu lớn (file PDF 100 trang) thành các miếng nhỏ (chunks) để nạp vào Vector DB.

**Học để làm gì?** Nếu cắt quá dài: tốn bộ nhớ, nhiễu thông tin. Nếu cắt quá ngắn: mất ngữ cảnh. Cần kỹ thuật **cắt gối đầu** (overlap).

<Callout type="warning" title="Lưu ý khi Chunking">
Chunk size phổ biến: 500-1000 tokens. Overlap: 10-20%. Kỹ thuật cắt phổ biến nhất: `RecursiveCharacterTextSplitter`.
</Callout>

**Thư viện:**
- **LangChain.js** (document loaders)
- **LlamaIndex.TS** (chuyên về xử lý data)

**Ví dụ đầu ra:** Một pipeline tự động: Upload file PDF -> Tự cắt nhỏ -> Lưu vào DB -> Sẵn sàng để chat.

---

## Giai đoạn 3: Điều phối luồng (Orchestration & Memory)

> Mục tiêu: Xây dựng ứng dụng chat phức tạp, nhớ được hội thoại.

### Conversation Memory Management

**Cái này là gì?** Cơ chế lưu và nạp lại lịch sử chat vào mỗi request mới gửi lên LLM.

**Học để làm gì?** LLM là **Stateless** (không có trạng thái). Bạn phải tự quản lý việc gửi kèm "User đã nói gì trước đó". Cần học cách quản lý khi lịch sử quá dài (tràn Context Window).

| Chiến lược | Cách hoạt động | Trade-off |
|---|---|---|
| Sliding Window | Chỉ giữ N tin nhắn mới nhất | Đơn giản, nhưng mất context cũ |
| Summarization | Dùng AI tóm tắt tin cũ | Giữ được ý chính, tốn thêm API call |
| Hybrid | Kết hợp cả hai | Tốt nhất nhưng phức tạp hơn |

**Thư viện:** **LangGraph** (Checkpointer), **Redis** (lưu session chat).

<Callout type="info" title="Ví dụ đầu ra">
Chatbot hỏi: "Bạn tên gì?", User: "Tên tôi là Huy". 10 câu sau User hỏi: "Tên tôi là gì?", Chatbot: "Bạn tên là Huy".
</Callout>

---

### Chains & Routing

**Cái này là gì?** Kết nối các bước xử lý tuần tự hoặc rẽ nhánh.

**Học để làm gì?** Xử lý logic phức tạp. Ví dụ: Nếu User hỏi về Code -> Gọi Model rẻ, code giỏi. Nếu hỏi về Văn học -> Gọi model văn hay.

**Ví dụ Routing:**

1. User gửi Input
2. Router phân loại câu hỏi
3. Nếu về Code → gọi Code Model
4. Nếu về Văn học → gọi Writing Model

**Thư viện:** **LangChain Expression Language** (LCEL) hoặc code thủ công (native code thường dễ debug hơn).

**Ví dụ đầu ra:** Một API endpoint duy nhất xử lý đa nhiệm: Vừa dịch thuật, vừa tóm tắt, vừa trích xuất dữ liệu tùy theo input.

---

## Giai đoạn 4: Agents (AI tự hành động)

> Mục tiêu: AI không chỉ "nói", mà còn "làm" (dùng Tool).

### Tool Calling (Function Calling)

**Cái này là gì?** Bạn mô tả hàm `sendEmail(to, body)` cho AI. AI sẽ trả về JSON bảo bạn: "Hãy chạy hàm sendEmail với tham số này...".

**Học để làm gì?** Biến AI từ một **người tư vấn** thành một **trợ lý thực thi**.

**Cách học:** Học cách viết docstring/description cho hàm thật kỹ (AI đọc cái này để hiểu cách dùng tool).

```typescript
// Ví dụ khai báo Tool cho AI
const tools = [{
  type: "function",
  function: {
    name: "sendEmail",
    description: "Gửi email cho một người",
    parameters: {
      type: "object",
      properties: {
        to: { type: "string", description: "Email người nhận" },
        body: { type: "string", description: "Nội dung email" },
      },
      required: ["to", "body"],
    },
  },
}];
```

**Tài liệu:** OpenAI Function Calling guide.

<Callout type="info" title="Ví dụ đầu ra">
User: "Gửi mail xin nghỉ cho sếp". AI tự gọi hàm gửi mail với nội dung xin nghỉ phép trang trọng.
</Callout>

---

### ReAct Pattern (Reason + Act)

**Cái này là gì?** Một vòng lặp tư duy: **Suy nghĩ** -> Quyết định dùng Tool -> Chờ kết quả -> **Quan sát** -> Suy nghĩ tiếp.

**Học để làm gì?** Giải quyết các bài toán cần nhiều bước. Ví dụ: "Tìm giá vé máy bay, sau đó so sánh với ngân sách của tôi". AI phải tìm vé trước, có giá rồi mới so sánh được.

**Vòng lặp ReAct:**

1. **Suy nghĩ (Reason)** — Phân tích vấn đề
2. **Hành động (Act)** — Gọi tool phù hợp
3. **Quan sát (Observe)** — Đọc kết quả trả về
4. **Kết luận (Answer)** — Trả lời hoặc lặp lại từ bước 1

**Framework:** **LangGraph** — framework mạnh nhất hiện nay cho Agent, thay thế dần LangChain Agent cũ.

**Ví dụ đầu ra:** Một Agent nghiên cứu thị trường: Tự search Google, đọc 5 trang web đầu, tổng hợp thông tin và viết báo cáo markdown.

---

## Giai đoạn 5: Production & LLMOps (Đưa vào thực tế)

> Mục tiêu: Chạy ổn định, rẻ, và biết nó sai ở đâu.

### Evaluation (Evals)

**Cái này là gì?** Unit Test cho AI. Làm sao biết sau khi sửa prompt, AI có trả lời ngu đi không?

**Học để làm gì?** Đảm bảo chất lượng sản phẩm trước khi release.

**Cách học:**
- Tạo bộ **"Golden Dataset"** (Câu hỏi + Câu trả lời mẫu).
- Dùng **"LLM-as-a-Judge"** (Dùng GPT-4 để chấm điểm câu trả lời của model nhỏ hơn).

**Thư viện:** **LangSmith**, **PromptFoo** (rất hay cho Dev).

<Callout type="info" title="Ví dụ đầu ra">
Một báo cáo CI/CD: "PR này làm giảm độ chính xác của chatbot đi 5%, block merge".
</Callout>

---

### Tracing & Observability

**Cái này là gì?** Log lại toàn bộ "Suy nghĩ" của AI.

**Học để làm gì?** Khi AI trả lời sai, bạn cần nhìn thấy nó đã nhận được context gì, nó đã gọi tool gì, tham số ra sao. `console.log` là không đủ.

| Tool | Loại | Điểm nổi bật |
|---|---|---|
| LangSmith | SaaS | Tích hợp tốt với LangChain/LangGraph |
| Arize Phoenix | Open-source | Self-hosted, UI trực quan |
| Helicone | SaaS | Proxy-based, dễ tích hợp |

**Ví dụ đầu ra:** Dashboard hiển thị: User A gặp lỗi, click vào xem thấy AI đã search Google sai từ khóa -> Fix prompt.

---

## Tổng kết: Roadmap tổng quan

Mỗi giai đoạn sẽ tăng dần độ phức tạp, nhưng cũng mở ra nhiều khả năng hơn:

- **Giai đoạn 1 (LLM Control):** Nền tảng — bắt đầu từ đây
- **Giai đoạn 2 (RAG):** Nạp dữ liệu riêng
- **Giai đoạn 3 (Orchestration):** Điều phối phức tạp
- **Giai đoạn 4 (Agents):** AI tự hành động
- **Giai đoạn 5 (Production):** Đưa vào thực tế

<Callout type="tip" title="Lời khuyên">
Bạn không cần học hết tất cả mới bắt đầu. Chỉ cần xong **Giai đoạn 1** là đã có thể build được ứng dụng AI cơ bản. Mỗi giai đoạn tiếp theo sẽ giúp bạn xử lý các bài toán phức tạp hơn.
</Callout>
